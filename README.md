# awesome-tta


### Classic TTA
- [**CLIPArTT**] CLIPArTT: Light-weight Adaptation of CLIP to New Domains at Test Time (ArXiv 24) [Paper](https://arxiv.org/pdf/2405.00754)
- [**ATTA**] Active Test-Time Adaptation: Theoretical Analyses and An Algorithm (ICLR 24) [Paper](https://arxiv.org/pdf/2404.05094.pdf) [Code](https://github.com/divelab/ATTA)
- [**GDA**] GDA: Generalized Diffusion for Robust Test-time Adaptation [Paper](https://arxiv.org/pdf/2404.00095.pdf) #diffusion
- [**TTT-KD**] TTT-KD: Test-Time Training for 3D Semantic Segmentation through Knowledge Distillation from Foundation Models [Paper](https://arxiv.org/pdf/2403.11691.pdf)
- [**CoDA**] CoDA: Instructive Chain-of-Domain Adaptation with Severity-Aware Visual Prompt Tuning (ArXiv 24) [Paper](https://arxiv.org/pdf/2403.17369.pdf)
- Robust Overfitting Does Matter: Test-Time Adversarial Purification With FGSM [Paper](https://arxiv.org/pdf/2403.11448.pdf) #augmentation #adversarial
- Efficient Diffusion-Driven Corruption Editor for Test-Time Adaptation [Paper](https://arxiv.org/pdf/2403.10911.pdf) #diffusion #augmentation
- Test-time Adaptation Meets Image Enhancement: Improving Accuracy via Uncertainty-aware Logit Switching (IJCNN 24) [Paper](https://arxiv.org/pdf/2403.17423.pdf)
- Bag of Tricks for Fully Test-Time Adaptation (WACV 24) [Paper](https://openaccess.thecvf.com/content/WACV2024/papers/Mounsaveng_Bag_of_Tricks_for_Fully_Test-Time_Adaptation_WACV_2024_paper.pdf)
- pSTarC: Pseudo Source Guided Target Clustering for Fully Test-Time Adaptation (WACV 24) [Paper](https://openaccess.thecvf.com/content/WACV2024/papers/Sreenivas_pSTarC_Pseudo_Source_Guided_Target_Clustering_for_Fully_Test-Time_Adaptation_WACV_2024_paper.pdf)
- REALM: Robust Entropy Adaptive Loss Minimization for Improved Single-Sample Test-Time Adaptation (WACV 24) [Paper](https://openaccess.thecvf.com/content/WACV2024/papers/Seto_REALM_Robust_Entropy_Adaptive_Loss_Minimization_for_Improved_Single-Sample_Test-Time_WACV_2024_paper.pdf)
- Universal Test-time Adaptation through Weight Ensembling, Diversity Weighting, and Prior Correction (WACV 24) [Paper](https://openaccess.thecvf.com/content/WACV2024/papers/Marsden_Universal_Test-Time_Adaptation_Through_Weight_Ensembling_Diversity_Weighting_and_Prior_WACV_2024_paper.pdf)
- Layer-wise Auto-Weighting for Non-Stationary Test-Time Adaptation (WACV 24) [Paper](https://openaccess.thecvf.com/content/WACV2024/papers/Park_Layer-Wise_Auto-Weighting_for_Non-Stationary_Test-Time_Adaptation_WACV_2024_paper.pdf)
- [**CAFA**] CAFA: Class-Aware Feature Alignment for Test-Time Adaptation (ICCV 23) [Paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Jung_CAFA_Class-Aware_Feature_Alignment_for_Test-Time_Adaptation_ICCV_2023_paper.pdf)
- Back to the Source: Diffusion-Driven Test-Time Adaptation (CVPR 23) [Paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Gao_Back_to_the_Source_Diffusion-Driven_Adaptation_To_Test-Time_Corruption_CVPR_2023_paper.pdf)
- [**SAR**] Towards Stable Test-Time Adaptation in Dynamic Wild World (ICLR 23) [Paper](https://arxiv.org/pdf/2302.12400.pdf)
- Test-Time Adaptation via Conjugate Pseudo-labels (NeurIPS 22) [Paper](https://proceedings.neurips.cc/paper_files/paper/2022/file/28e9eff897f98372409b40ae1ed3ea4c-Paper-Conference.pdf)

### Continual TTA
- [**AETTA**] AETTA: Label-Free Accuracy Estimation for Test-Time Adaptation (CVPR 24) [Paper](https://arxiv.org/pdf/2404.01351.pdf)
- [**Continual-MAE**] Continual-MAE: Adaptive Distribution Masked Autoencoders for Continual Test-Time Adaptation (ArXiv 24) [Paper](https://arxiv.org/pdf/2312.12480.pdf)
- [**EATA-C**] Uncertainty-calibrated test-time model adaptation without forgetting (ArXiv 24) [Paper](https://arxiv.org/pdf/2403.11491.pdf)
- [**ViDA**] ViDA: Homeostatic Visual Domain Adapter for Continual Test Time Adaptation (ICLR 24) [Paper](https://arxiv.org/pdf/2306.04344)
- [**PALM**] PALM: Pushing Adaptive Learning Rate Mechanisms for Continual Test-Time Adaptation (ArXiv 24) [Paper](https://arxiv.org/pdf/2403.10650.pdf)
- [**BeCoTTA**] BECoTTA: Input-dependent Online Blending of Experts for Continual Test-time Adaptation (ArXiv 24) [Paper](https://arxiv.org/pdf/2402.08712.pdf)
- [**DSS**] Continual Test-time Domain Adaptation via Dynamic Sample Selection (WACV 24) [Paper](https://openaccess.thecvf.com/content/WACV2024/papers/Wang_Continual_Test-Time_Domain_Adaptation_via_Dynamic_Sample_Selection_WACV_2024_paper.pdf)
- Effective Restoration of Source Knowledge in Continual Test-Time Adaptation (WACV 24) [Paper](https://openaccess.thecvf.com/content/WACV2024/papers/Niloy_Effective_Restoration_of_Source_Knowledge_in_Continual_Test_Time_Adaptation_WACV_2024_paper.pdf)
- [**CoDAG**] Complementary domain adaptation and generalization for unsupervised continual domain shift learning (ICCV 23) [Paper](https://arxiv.org/pdf/2303.15833.pdf)
- [**VDP**] Decorate the newcomers: Visual domain prompt for continual test time adaptation (AAAI 23) [Paper](https://arxiv.org/pdf/2212.04145)
- [**ECoTTA**] EcoTTA: Memory-Efficient Continual Test-time Adaptation via Self-distilled Regularization (CVPR 23) [Paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Song_EcoTTA_Memory-Efficient_Continual_Test-Time_Adaptation_via_Self-Distilled_Regularization_CVPR_2023_paper.pdf)
- [**PETAL**] A Probabilistic Framework for Lifelong Test-Time Adaptation (CVPR 23) [Paper](https://arxiv.org/pdf/2212.09713.pdf)
- [**Diffusion-TTA**]: Test-time Adaptation of Discriminative Models via Generative Feedback (NeurIPS 23) [Paper](https://arxiv.org/pdf/2311.16102) #diffusion
- [**EATA**] Efficient Test-Time Model Adaptation without Forgetting (ICML 22) [Paper](https://arxiv.org/pdf/2204.02610.pdf)
- [**CoTTA**] Continual Test-Time Domain Adaptation (CVPR 22) [Paper](https://arxiv.org/pdf/2203.13591.pdf)

### Test-Time Prompt Tuning
- [**TFUP-T**] Training-Free Unsupervised Prompt for Vision-Language Models (ArXiv 24) [Paper](https://arxiv.org/pdf/2404.16339) [Code](https://github.com/wlb12345/TFUP) #DomainNet
- [**PromptSync**] PromptSync: Bridging Domain Gaps in Vision-Language Models through Class-Aware Prototype Alignment and Discrimination (ArXiv 24) [Paper](https://arxiv.org/pdf/2404.07520.pdf)
- [**TDA**] Efficient Test-Time Adaptation of Vision-Language Models (CVPR 24) [Paper](https://arxiv.org/pdf/2403.18293.pdf) [Code](https://github.com/kdiAAA/TDA)
- [**TPS**] Just Shift It: Test-Time Prototype Shifting for Zero-Shot Generalization with Vision-Language Models (ArXiv 24) [Paper](https://arxiv.org/pdf/2403.12952.pdf)
- [**C-TPT**]: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion (ICLR 24) [Paper](https://arxiv.org/pdf/2403.14119.pdf)
- Test-Time Adaptation with CLIP Reward for Zero-Shot Generalization in Vision-Language Models (ICLR 24) [Paper](https://arxiv.org/pdf/2305.18010)
- [**VPA**] VPA: Fully Test-Time Visual Prompt Adaptation (ACMM 23) [Paper](https://dl.acm.org/doi/pdf/10.1145/3581783.3611835)
- [**PromptAlign**] Align Your Prompts: Test-Time Prompting with Distribution Alignment for Zero-Shot Generalization [Paper](https://arxiv.org/pdf/2311.01459)
- [**SwapPrompt**] SwapPrompt: Test-Time Prompt Adaptation for Vision-Language Models (NeurIPS 23) [Paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/cdd0640218a27e9e2c0e52e324e25db0-Paper-Conference.pdf)
- [**DiffTPT**] Diverse Data Augmentation with Diffusions for Effective Test-time Prompt Tuning (ICCV 23) [Paper](https://arxiv.org/pdf/2308.06038) #diffusion
- [**TPT**] Test-Time Prompt Tuning for Zero-shot Generalization in Vision-Language Models (NeurIPS 22) [Paper](https://arxiv.org/pdf/2209.07511.pdf)

### Other
- [**MoE-Adapters4CL**] Boosting Continual Learning of Vision-Language Models via Mixture-of-Experts Adapters (CVPR 24) [Paper](https://arxiv.org/pdf/2403.11549) [Code](https://github.com/JiazuoYu/MoE-Adapters4CL)
- [**CoLeCLIP**] CoLeCLIP: Open-Domain Continual Learning via Joint Task Prompt and Vocabulary Learning (ArXiv 24) [Paper](https://arxiv.org/pdf/2403.10245.pdf)
- [**ZSCL**] Preventing Zero-Shot Transfer Degradation in Continual Learning of Vision-Language Models (ICCV 23) [Paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Preventing_Zero-Shot_Transfer_Degradation_in_Continual_Learning_of_Vision-Language_Models_ICCV_2023_paper.pdf)

---
Prerequisites:
- [Tip-Adapter: Training-free Adaption of CLIP for Few-shot Classification (ECCV 22)](https://arxiv.org/pdf/2207.09519.pdf)
- [The Power of Scale for Parameter-Efficient Prompt Tuning (EMNLP 21)](https://arxiv.org/abs/2104.08691) #prompt-tuning
- [Learning Transferable Visual Models From Natural Language Supervision (ICML 21)](https://arxiv.org/abs/2103.00020) #clip
